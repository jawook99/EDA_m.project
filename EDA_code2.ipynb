{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 1] 환경 설정 및 라이브러리 임포트\n",
    "# 목적: 시각화 폰트, 경고 설정, 결과 저장 경로 준비\n",
    "import os, platform, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from itertools import combinations\n",
    "\n",
    "# 선택적: ML/설명가능성 패키지 (없으면 자동 스킵)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception:\n",
    "    HAS_SHAP = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 한글 폰트 설정\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "elif platform.system() == 'Darwin':\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "else:\n",
    "    plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (11, 7)\n",
    "\n",
    "# 결과물 저장 폴더\n",
    "FIG_DIR = \"figs\"\n",
    "REPORT_DIR = \"reports\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"환경 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3034aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 2] 데이터 로드 및 기본 전처리\n",
    "# 목적: 파일 로드, 핵심 수치형 정제, 컬럼 매핑 준비\n",
    "FILE = \"merged_data.csv\"  # 필요시 교체\n",
    "\n",
    "# 유연한 인코딩 로드\n",
    "try:\n",
    "    df = pd.read_csv(FILE, encoding=\"utf-8-sig\", low_memory=False)\n",
    "except UnicodeError:\n",
    "    df = pd.read_csv(FILE, encoding=\"utf-8\", low_memory=False)\n",
    "\n",
    "print(f\"데이터 파일 '{FILE}' 로드 완료. 원본 크기: {df.shape}\")\n",
    "\n",
    "# 핵심 수치형 정리\n",
    "for col in [\"사망자수\", \"중상자수\", \"경상자수\"]:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df = df.dropna(subset=['사망자수', '중상자수', '경상자수']).copy()\n",
    "df[['사망자수','중상자수','경상자수']] = df[['사망자수','중상자수','경상자수']].fillna(0)\n",
    "\n",
    "# 유연한 컬럼명 매핑 테이블\n",
    "col_map = {\n",
    "    '사고월': ['사고월', '월'],\n",
    "    '운전자연령': ['일당운전자연령', '가해운전자.연령대', '가해운전자연령', '운전자연령'],\n",
    "    '사고장소': ['사고장소', '사고지역', '시군구', '시군구_only'],\n",
    "    '사고유형': ['사고유형1', '사고유형'],\n",
    "    '도로형태': ['도로형태'],\n",
    "    '사고시각': ['사고시각'],\n",
    "    '노면상태': ['노면상태'],\n",
    "    '성별': ['일당운전자성별', '가해운전자.성별', '운전자성별'],\n",
    "    '도로종류': ['도로종류'],\n",
    "    '법규위반': ['법규위반'],\n",
    "    '기상상태': ['기상상태'],\n",
    "    '사고일자': ['사고일자_날짜', '발생년월_dt', '사고일자', '발생년월']\n",
    "}\n",
    "\n",
    "def get_col(df_, candidates):\n",
    "    for name in candidates:\n",
    "        if name in df_.columns:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "print(\"기본 전처리 및 컬럼 매핑 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 3] 안전 파서: '사고월' → '계절'\n",
    "month_col = get_col(df, col_map['사고월'])\n",
    "\n",
    "if month_col:\n",
    "    df[month_col] = pd.to_numeric(df[month_col], errors='coerce').astype('Int64')\n",
    "\n",
    "    def get_season(m):\n",
    "        if pd.isna(m): return np.nan\n",
    "        m = int(m)\n",
    "        if m in (3,4,5):  return '봄'\n",
    "        if m in (6,7,8):  return '여름'\n",
    "        if m in (9,10,11): return '가을'\n",
    "        return '겨울'\n",
    "\n",
    "    df['계절'] = df[month_col].apply(get_season)\n",
    "    print(f\"'{month_col}' 기반 '계절' 생성 완료.\")\n",
    "else:\n",
    "    print(\"계절 생성 불가: '사고월'/'월' 컬럼 없음.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 4] 안전 파서: '사고시각' → '사고시간대'\n",
    "time_col = get_col(df, col_map['사고시각'])\n",
    "\n",
    "def safe_hour(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    # HHMM 순수숫자\n",
    "    if s.isdigit() and len(s) in (3,4):\n",
    "        try:\n",
    "            h = int(s[:-2]) if len(s) == 4 else int(s[0])\n",
    "            return h if 0 <= h <= 23 else np.nan\n",
    "        except:\n",
    "            return np.nan\n",
    "    # HH, HH.0 등\n",
    "    try:\n",
    "        h = int(float(s))\n",
    "        return h if 0 <= h <= 23 else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if time_col:\n",
    "    hrs = df[time_col].apply(safe_hour)\n",
    "\n",
    "    def get_time_slot(h):\n",
    "        if pd.isna(h): return np.nan\n",
    "        h = int(h)\n",
    "        if 0 <= h <= 5:   return '심야(0~5시)'\n",
    "        if 6 <= h <= 9:   return '출근(6~9시)'\n",
    "        if 10 <= h <= 17: return '낮(10~17시)'\n",
    "        if 18 <= h <= 21: return '퇴근(18~21시)'\n",
    "        return '밤(22~23시)'\n",
    "\n",
    "    df['사고시간대'] = hrs.apply(get_time_slot)\n",
    "    print(f\"'{time_col}' 기반 '사고시간대' 생성 완료.\")\n",
    "else:\n",
    "    print(\"시간대 생성 불가: '사고시각' 컬럼 없음.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbfb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 5] 안전 파서: '운전자연령' → '운전자연령대'\n",
    "age_col = get_col(df, col_map['운전자연령'])\n",
    "\n",
    "def parse_age(v):\n",
    "    if pd.isna(v): return np.nan\n",
    "    s = str(v).strip()\n",
    "    if s.isdigit(): return int(s)\n",
    "    s = s.replace(' ', '')\n",
    "    for token in ['세', '살', '이상', '이하', '대']:\n",
    "        s = s.replace(token, '')\n",
    "    try:\n",
    "        return int(float(s))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def to_age_group(age):\n",
    "    if pd.isna(age): return np.nan\n",
    "    a = int(age)\n",
    "    if a < 30: return '20대이하'\n",
    "    if a < 40: return '30대'\n",
    "    if a < 50: return '40대'\n",
    "    if a < 60: return '50대'\n",
    "    return '60대이상'\n",
    "\n",
    "if age_col:\n",
    "    ages = df[age_col].apply(parse_age)\n",
    "    df['운전자연령대'] = ages.apply(to_age_group)\n",
    "    print(f\"'{age_col}' 기반 '운전자연령대' 생성 완료.\")\n",
    "else:\n",
    "    print(\"연령대 생성 불가: 연령 컬럼 없음.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 6] 시공간 정교화: 날짜 파싱 및 파생\n",
    "date_col = get_col(df, col_map['사고일자'])\n",
    "\n",
    "def parse_date_safe(s):\n",
    "    if pd.isna(s): return pd.NaT\n",
    "    # 'YYYY-MM-DD', 'YYYYMM', 'YYYY.MM', 'YYYY/MM' 등 유연 처리\n",
    "    v = str(s).strip()\n",
    "    try:\n",
    "        # 일반 날짜\n",
    "        return pd.to_datetime(v, errors='coerce', format=None)\n",
    "    except:\n",
    "        pass\n",
    "    # 연월만 있는 경우엔 1일로 보정\n",
    "    for sep in ['.', '-', '/', ' ']:\n",
    "        parts = v.split(sep)\n",
    "        if len(parts) == 2 and all(p.isdigit() for p in parts):\n",
    "            try:\n",
    "                y, m = int(parts[0]), int(parts[1])\n",
    "                return pd.to_datetime(f\"{y:04d}-{m:02d}-01\", errors='coerce')\n",
    "            except:\n",
    "                return pd.NaT\n",
    "    # 순수 연월(YYYYMM)\n",
    "    if v.isdigit() and len(v) == 6:\n",
    "        try:\n",
    "            y, m = int(v[:4]), int(v[4:])\n",
    "            return pd.to_datetime(f\"{y:04d}-{m:02d}-01\", errors='coerce')\n",
    "        except:\n",
    "            return pd.NaT\n",
    "    return pd.to_datetime(v, errors='coerce')\n",
    "\n",
    "if date_col:\n",
    "    dt = df[date_col].apply(parse_date_safe)\n",
    "    df['사고일자_dt'] = dt\n",
    "    df['요일'] = df['사고일자_dt'].dt.day_name()\n",
    "    df['주말여부'] = df['요일'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "    df['분기'] = df['사고일자_dt'].dt.quarter\n",
    "    # 러시아워 플래그\n",
    "    df['러시아워'] = df['사고시간대'].isin(['출근(6~9시)', '퇴근(18~21시)']).astype(int)\n",
    "    print(f\"'{date_col}' 기반 시공간 파생 생성 완료.\")\n",
    "else:\n",
    "    print(\"시공간 파생 일부 제한: 날짜 컬럼 없음.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 7] 통합지수 계산 및 도로별 집계 병합\n",
    "df[\"다발도\"] = (df[\"사망자수\"].gt(0)).astype(float) * 1.0 \\\n",
    "             + (df[\"중상자수\"].gt(0)).astype(float) * 0.7 \\\n",
    "             + (df[\"경상자수\"].gt(0)).astype(float) * 0.3\n",
    "df[\"심각도\"] = df[\"사망자수\"] * 1.0 + df[\"중상자수\"] * 0.7 + df[\"경상자수\"] * 0.3\n",
    "df[\"통합지수\"] = df[\"다발도\"] * 0.4 + df[\"심각도\"] * 0.6\n",
    "print(\"통합지수 계산 완료. (정규화 없음)\")\n",
    "\n",
    "place_col = get_col(df, col_map['사고장소'])\n",
    "if place_col:\n",
    "    agg_place = (\n",
    "        df.groupby(place_col, as_index=False)['통합지수']\n",
    "          .sum()\n",
    "          .rename(columns={'통합지수': '통합지수_합계'})\n",
    "    )\n",
    "    df_ = df.merge(agg_place, on=place_col, how='left')\n",
    "    print(f\"도로별 집계 병합 완료. df_ shape: {df_.shape}\")\n",
    "else:\n",
    "    print(\"도로별 집계 불가: '사고장소'/'사고지역'/'시군구' 중 해당 없음.\")\n",
    "    df_ = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f723bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 8] 범주 정제 및 통합\n",
    "violation_raw = get_col(df_, col_map['법규위반']) if not df_.empty else None\n",
    "\n",
    "if violation_raw:\n",
    "    violation_map = {\n",
    "        '과속': '과속',\n",
    "        '제한속도위반': '과속',\n",
    "        '신호위반': '신호/통행위반',\n",
    "        '통행금지위반': '신호/통행위반',\n",
    "        '보행자보호의무위반': '신호/통행위반',\n",
    "        '중앙선침범': '차로/진로위반',\n",
    "        '진로변경위반': '차로/진로위반',\n",
    "        '차로위반': '차로/진로위반',\n",
    "        '안전거리미확보': '안전거리미확보'\n",
    "    }\n",
    "    df_['법규위반_대분류'] = df_[violation_raw].map(violation_map).fillna('기타')\n",
    "    print(\"법규위반 대분류 생성 완료.\")\n",
    "else:\n",
    "    print(\"법규위반 통합 생략: 해당 컬럼 없음.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55518191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 9] 통계 유틸 + 신뢰구간 + 요약 텍스트\n",
    "def _fmt(x, fmt=\".3f\"):\n",
    "    try:\n",
    "        if x is None or (isinstance(x, float) and np.isnan(x)): return \"nan\"\n",
    "        return format(x, fmt)\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "def mean_ci(series, alpha=0.05):\n",
    "    arr = np.array(series.dropna())\n",
    "    n = len(arr)\n",
    "    if n == 0:\n",
    "        return np.nan, (np.nan, np.nan), n\n",
    "    m = np.mean(arr)\n",
    "    se = stats.sem(arr)\n",
    "    if n > 1 and np.isfinite(se):\n",
    "        ci_low, ci_high = stats.t.interval(1 - alpha, n - 1, loc=m, scale=se)\n",
    "    else:\n",
    "        ci_low, ci_high = np.nan, np.nan\n",
    "    return m, (ci_low, ci_high), n\n",
    "\n",
    "def kruskal_overall(tmp: pd.DataFrame, col: str, metric: str):\n",
    "    if (col not in tmp.columns) or (metric not in tmp.columns):\n",
    "        return np.nan, np.nan, 0\n",
    "    groups = [g[metric].dropna().values for _, g in tmp.groupby(col)]\n",
    "    groups = [g for g in groups if len(g) > 0]\n",
    "    if len(groups) < 2:\n",
    "        return np.nan, np.nan, len(groups)\n",
    "    H, p = stats.kruskal(*groups)\n",
    "    return H, p, len(groups)\n",
    "\n",
    "def generate_summary_with_ci(df_source: pd.DataFrame, col: str, metric: str, topn=3):\n",
    "    if col not in df_source.columns or metric not in df_source.columns:\n",
    "        return f\"[{col}] 분석 불가: 필요한 컬럼 없음.\"\n",
    "    tmp = df_source.dropna(subset=[col])[[col, metric]].copy()\n",
    "    if tmp.empty:\n",
    "        return f\"[{col}] 분석 불가: 유효 데이터 없음.\"\n",
    "\n",
    "    # 그룹별 평균 및 95% CI\n",
    "    rows = []\n",
    "    for k, g in tmp.groupby(col):\n",
    "        mean_val, (ci_l, ci_h), n = mean_ci(g[metric])\n",
    "        rows.append((k, mean_val, ci_l, ci_h, n))\n",
    "    stats_df = pd.DataFrame(rows, columns=['그룹','평균','CI하한','CI상한','표본수']).sort_values('평균', ascending=False)\n",
    "\n",
    "    # 전체 유의성\n",
    "    H, p, _ = kruskal_overall(tmp.rename(columns={col: \"grp\", metric: \"val\"}), \"grp\", \"val\")\n",
    "\n",
    "    # 요약 문구\n",
    "    head = stats_df.head(min(topn, len(stats_df)))\n",
    "    tail = stats_df.tail(min(topn, len(stats_df)))\n",
    "    def to_items(df_):\n",
    "        return \", \".join([f\"{r['그룹']}({_fmt(r['평균'])}, [{_fmt(r['CI하한'])}, {_fmt(r['CI상한'])}], n={int(r['표본수'])})\" for _, r in df_.iterrows()])\n",
    "    text = []\n",
    "    text.append(f\"[{col}] Kruskal–Wallis H={_fmt(H)}, p={_fmt(p, '.3g')}\")\n",
    "    text.append(f\"- 상위 {len(head)}: {to_items(head)}\")\n",
    "    text.append(f\"- 하위 {len(tail)}: {to_items(tail)}\")\n",
    "    return \"\\n\".join(text), stats_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a3b09",
   "metadata": {},
   "source": [
    "## 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 10] 단일 변수 시각화 + 신뢰구간 표 + 유의미성 문구\n",
    "report_lines = []\n",
    "\n",
    "def save_group_ci_table(stats_df, name):\n",
    "    path = os.path.join(REPORT_DIR, f\"ci_{name}.csv\")\n",
    "    stats_df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    return path\n",
    "\n",
    "if not df_.empty:\n",
    "    print(\"\\n--- 단일 변수 시각화 및 통계 분석 ---\")\n",
    "\n",
    "    # 1) 사고장소별 통합지수 합계 Top 10\n",
    "    place_col = get_col(df_, col_map['사고장소'])\n",
    "    if place_col:\n",
    "        top10 = df_.groupby(place_col)['통합지수'].sum().nlargest(10).reset_index()\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='통합지수', y=place_col, data=top10)\n",
    "        plt.title('사고장소별 통합지수 합계 Top 10')\n",
    "        plt.xlabel('통합지수 합계'); plt.ylabel('사고장소')\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, 'place_top10_totalrisk.png')); plt.show()\n",
    "\n",
    "        text, _ = generate_summary_with_ci(df_, place_col, '통합지수', topn=3)\n",
    "        print(text); report_lines += [\"[그림] 사고장소 Top10\", text, \"\"]\n",
    "    else:\n",
    "        print(\"[경고] 사고장소 컬럼 없음.\")\n",
    "\n",
    "    # 2) 도로종류별 통합지수 분포(Box) + CI 표\n",
    "    road_kind_col = get_col(df_, col_map['도로종류'])\n",
    "    if road_kind_col:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(x=df_[road_kind_col], y=df_['통합지수'])\n",
    "        plt.title('도로종류별 통합지수 분포')\n",
    "        plt.xlabel('도로종류'); plt.ylabel('통합지수')\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, 'box_roadkind_totalrisk.png')); plt.show()\n",
    "\n",
    "        text, stats_df = generate_summary_with_ci(df_, road_kind_col, '통합지수', topn=3)\n",
    "        path = save_group_ci_table(stats_df, \"roadkind\")\n",
    "        print(text); report_lines += [\"[그림] 도로종류 분포\", text, f\"CI 표: {path}\", \"\"]\n",
    "    else:\n",
    "        print(\"[경고] 도로종류 컬럼 없음.\")\n",
    "\n",
    "    # 3) 월별 사고 건수 추이(Line)\n",
    "    month_col = get_col(df_, col_map['사고월'])\n",
    "    if month_col:\n",
    "        monthly_cnt = df_.groupby(month_col).size()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.lineplot(x=monthly_cnt.index, y=monthly_cnt.values, marker='o')\n",
    "        plt.title('월별 사고 건수 추이')\n",
    "        plt.xlabel('월'); plt.ylabel('사고 건수')\n",
    "        plt.xticks(monthly_cnt.index); plt.grid(True)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, 'line_monthly_count.png')); plt.show()\n",
    "        report_lines += [\"[그림] 월별 사고 건수\", \"설명: 추세 확인(평균 비교 검정 대상 아님).\", \"\"]\n",
    "    else:\n",
    "        print(\"[경고] 사고월 컬럼 없음.\")\n",
    "\n",
    "    # 4) 사고시간대별 평균 통합지수 + CI\n",
    "    if '사고시간대' in df_.columns:\n",
    "        text, stats_df = generate_summary_with_ci(df_, '사고시간대', '통합지수', topn=3)\n",
    "        path = save_group_ci_table(stats_df, \"timeslot\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        order = stats_df.sort_values('평균', ascending=False)['그룹']\n",
    "        sns.barplot(x='그룹', y='평균', data=stats_df, order=order)\n",
    "        plt.title('사고시간대별 평균 통합지수 (점추정)')\n",
    "        plt.xlabel('사고시간대'); plt.ylabel('평균 통합지수')\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, 'bar_timeslot_meanrisk.png')); plt.show()\n",
    "        print(text); report_lines += [\"[그림] 사고시간대 평균\", text, f\"CI 표: {path}\", \"\"]\n",
    "    else:\n",
    "        print(\"[경고] 사고시간대 컬럼 없음.\")\n",
    "\n",
    "    # 5) 법규위반 대분류별 평균 통합지수 + CI\n",
    "    if '법규위반_대분류' in df_.columns:\n",
    "        text, stats_df = generate_summary_with_ci(df_, '법규위반_대분류', '통합지수', topn=3)\n",
    "        path = save_group_ci_table(stats_df, \"violation_grouped\")\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        order = stats_df.sort_values('평균', ascending=False)['그룹']\n",
    "        sns.barplot(x='그룹', y='평균', data=stats_df, order=order)\n",
    "        plt.title('법규위반 대분류별 평균 통합지수 (점추정)')\n",
    "        plt.xlabel('법규위반 대분류'); plt.ylabel('평균 통합지수')\n",
    "        plt.xticks(rotation=30, ha='right')\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, 'bar_violation_grouped_meanrisk.png')); plt.show()\n",
    "        print(text); report_lines += [\"[그림] 법규위반 대분류 평균\", text, f\"CI 표: {path}\", \"\"]\n",
    "    else:\n",
    "        print(\"[경고] 법규위반 대분류 컬럼 없음.\")\n",
    "else:\n",
    "    print(\"df_ 비어있음: 단일 변수 시각화 생략\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 11] 복합 변수 히트맵 + 행/열 유의성 요약\n",
    "def heatmap_mean(df_in, idx, col, val='통합지수', title='', fname='heatmap.png', cmap='Oranges'):\n",
    "    pv = df_in.pivot_table(index=idx, columns=col, values=val, aggfunc='mean')\n",
    "    if pv.empty: return False\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(pv, cmap=cmap, annot=True, fmt=\".2f\", linewidths=.5, linecolor='white')\n",
    "    plt.title(title); plt.xlabel(col); plt.ylabel(idx)\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, fname)); plt.show()\n",
    "    return True\n",
    "\n",
    "def rowcol_significance(df_in, row, col, metric='통합지수'):\n",
    "    pv = df_in.pivot_table(index=row, columns=col, values=metric, aggfunc='mean')\n",
    "    rows, cols = [], []\n",
    "    if not pv.empty:\n",
    "        for r in pv.index:\n",
    "            sub = df_in.loc[df_in[row] == r, [col, metric]].rename(columns={col: \"grp\", metric: \"val\"})\n",
    "            H, p, _ = kruskal_overall(sub, \"grp\", \"val\")\n",
    "            rows.append((r, p))\n",
    "        for c in pv.columns:\n",
    "            sub = df_in.loc[df_in[col] == c, [row, metric]].rename(columns={row: \"grp\", metric: \"val\"})\n",
    "            H, p, _ = kruskal_overall(sub, \"grp\", \"val\")\n",
    "            cols.append((c, p))\n",
    "    row_sig = sum(1 for _, p in rows if not np.isnan(p) and p < 0.05)\n",
    "    col_sig = sum(1 for _, p in cols if not np.isnan(p) and p < 0.05)\n",
    "    return row_sig, len(rows), col_sig, len(cols)\n",
    "\n",
    "if not df_.empty:\n",
    "    # 1) 운전자연령대 × 법규위반 대분류\n",
    "    if ('운전자연령대' in df_.columns) and ('법규위반_대분류' in df_.columns):\n",
    "        if heatmap_mean(df_, '운전자연령대', '법규위반_대분류', '통합지수',\n",
    "                        '운전자연령대 × 법규위반 대분류 평균 통합지수', 'hm_age_violation.png', 'Oranges'):\n",
    "            rs, rn, cs, cn = rowcol_significance(df_, '운전자연령대', '법규위반_대분류')\n",
    "            line = f\"[운전자연령대×법규위반_대분류] 행 유의 {rs}/{rn}, 열 유의 {cs}/{cn}\"\n",
    "            print(line); report_lines += [\"[그림] 운전자연령대×법규위반\", line, \"\"]\n",
    "\n",
    "    # 2) 계절 × 기상상태\n",
    "    if ('계절' in df_.columns) and (get_col(df_, col_map['기상상태']) is not None):\n",
    "        wcol = get_col(df_, col_map['기상상태'])\n",
    "        if heatmap_mean(df_, '계절', wcol, '통합지수',\n",
    "                        '계절 × 기상상태 평균 통합지수', 'hm_season_weather.png', 'Blues'):\n",
    "            rs, rn, cs, cn = rowcol_significance(df_, '계절', wcol)\n",
    "            line = f\"[계절×{wcol}] 행 유의 {rs}/{rn}, 열 유의 {cs}/{cn}\"\n",
    "            print(line); report_lines += [\"[그림] 계절×기상상태\", line, \"\"]\n",
    "\n",
    "    # 3) 사고유형 × 법규위반 대분류\n",
    "    type_col = get_col(df_, col_map['사고유형'])\n",
    "    if (type_col is not None) and ('법규위반_대분류' in df_.columns):\n",
    "        if heatmap_mean(df_, type_col, '법규위반_대분류', '통합지수',\n",
    "                        '사고유형 × 법규위반 대분류 평균 통합지수', 'hm_type_violation.png', 'Greens'):\n",
    "            rs, rn, cs, cn = rowcol_significance(df_, type_col, '법규위반_대분류')\n",
    "            line = f\"[{type_col}×법규위반_대분류] 행 유의 {rs}/{rn}, 열 유의 {cs}/{cn}\"\n",
    "            print(line); report_lines += [\"[그림] 사고유형×법규위반\", line, \"\"]\n",
    "\n",
    "    # 4) 사고유형 × 도로형태\n",
    "    road_type_col = get_col(df_, col_map['도로형태'])\n",
    "    if (type_col is not None) and (road_type_col is not None):\n",
    "        if heatmap_mean(df_, type_col, road_type_col, '통합지수',\n",
    "                        '사고유형 × 도로형태 평균 통합지수', 'hm_type_road.png', 'Purples'):\n",
    "            rs, rn, cs, cn = rowcol_significance(df_, type_col, road_type_col)\n",
    "            line = f\"[{type_col}×{road_type_col}] 행 유의 {rs}/{rn}, 열 유의 {cs}/{cn}\"\n",
    "            print(line); report_lines += [\"[그림] 사고유형×도로형태\", line, \"\"]\n",
    "\n",
    "    # 5) 사고시간대 × 도로형태\n",
    "    if ('사고시간대' in df_.columns) and (road_type_col is not None):\n",
    "        if heatmap_mean(df_, '사고시간대', road_type_col, '통합지수',\n",
    "                        '사고시간대 × 도로형태 평균 통합지수', 'hm_time_road.png', 'PuRd'):\n",
    "            rs, rn, cs, cn = rowcol_significance(df_, '사고시간대', road_type_col)\n",
    "            line = f\"[사고시간대×{road_type_col}] 행 유의 {rs}/{rn}, 열 유의 {cs}/{cn}\"\n",
    "            print(line); report_lines += [\"[그림] 사고시간대×도로형태\", line, \"\"]\n",
    "else:\n",
    "    print(\"df_ 비어있음: 복합 히트맵 생략\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d3400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 12] 특징 조합 유의성 분석\n",
    "# 질문 1: 상위 하위 100개의 특징들 중 몇 개의 조합 이상일 때 유의미하게 증감이 나타나는지\n",
    "# 질문 2: 어떤 조합이 유의미한 증감을 보이는지\n",
    "\n",
    "# 분석에 사용할 특징 후보 (실제 존재하는 것만 사용)\n",
    "candidate_feats = []\n",
    "for k in ['계절', '운전자연령대', '사고시간대', '도로종류', '법규위반_대분류', '기상상태', '도로형태', '노면상태', '성별', '주말여부', '분기', '러시아워']:\n",
    "    if k in df_.columns:\n",
    "        candidate_feats.append(k)\n",
    "\n",
    "def combo_significance(df_in, feature_list, metric='통합지수', max_combos_per_r=1000):\n",
    "    results = []\n",
    "    for r in range(1, len(feature_list)+1):\n",
    "        combos = list(combinations(feature_list, r))\n",
    "        # 너무 많은 조합이면 상위 일부만 샘플 (범주 수가 큰 피처 우선)\n",
    "        if len(combos) > max_combos_per_r:\n",
    "            # 간단한 휴리스틱: 이름 길이 기준 정렬 후 앞부분 샘플\n",
    "            combos = sorted(combos, key=lambda x: sum(len(c) for c in x))[:max_combos_per_r]\n",
    "        for combo in combos:\n",
    "            grp = df_in.groupby(list(combo))[metric]\n",
    "            if grp.ngroups < 2:\n",
    "                continue\n",
    "            groups = [g.dropna().values for _, g in grp]\n",
    "            if all(len(g) > 0 for g in groups):\n",
    "                try:\n",
    "                    H, p = stats.kruskal(*groups)\n",
    "                except Exception:\n",
    "                    H, p = np.nan, np.nan\n",
    "            else:\n",
    "                H, p = np.nan, np.nan\n",
    "            results.append((combo, r, grp.ngroups, H, p))\n",
    "    return pd.DataFrame(results, columns=['특징조합','조합크기','그룹수','H','p'])\n",
    "\n",
    "if not df_.empty and len(candidate_feats) >= 1:\n",
    "    res_df = combo_significance(df_, candidate_feats, '통합지수', max_combos_per_r=2000)\n",
    "    # 조합 크기별 유의 비율\n",
    "    size_sig_ratio = res_df.groupby('조합크기').apply(lambda g: (g['p'] < 0.05).mean()).rename('p<0.05 비율')\n",
    "    print(\"[조합 크기별 유의 비율]\")\n",
    "    print(size_sig_ratio)\n",
    "\n",
    "    # 유의미 조합 Top 30\n",
    "    sig_combos = res_df[res_df['p'] < 0.05].sort_values('p').head(30).copy()\n",
    "\n",
    "    # 조합별 효과 크기 대략 보기: 그룹별 평균 범위(최대-최소)\n",
    "    effect_rows = []\n",
    "    for combo in sig_combos['특징조합']:\n",
    "        means = df_.groupby(list(combo))['통합지수'].mean()\n",
    "        rng = means.max() - means.min()\n",
    "        effect_rows.append((combo, rng, len(means)))\n",
    "    effect_df = pd.DataFrame(effect_rows, columns=['특징조합','평균범위(대략효과)','그룹수']).sort_values('평균범위(대략효과)', ascending=False)\n",
    "\n",
    "    # 저장\n",
    "    path_all = os.path.join(REPORT_DIR, \"combo_significance_all.csv\")\n",
    "    path_sig = os.path.join(REPORT_DIR, \"combo_significance_sigTop30.csv\")\n",
    "    path_eff = os.path.join(REPORT_DIR, \"combo_effectsize_sigTop30.csv\")\n",
    "    res_df.to_csv(path_all, index=False, encoding=\"utf-8-sig\")\n",
    "    sig_combos.to_csv(path_sig, index=False, encoding=\"utf-8-sig\")\n",
    "    effect_df.to_csv(path_eff, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    report_lines += [\n",
    "        \"[특징 조합 유의성]\",\n",
    "        f\"- 조합 크기별 p<0.05 비율:\\n{size_sig_ratio.to_string()}\",\n",
    "        f\"- 유의미 조합 Top30: {path_sig}\",\n",
    "        f\"- 유의미 조합 효과크기 Top30(평균범위): {path_eff}\",\n",
    "        \"\"\n",
    "    ]\n",
    "else:\n",
    "    print(\"특징 조합 분석 생략: df_ 비어있거나 특징 후보 부족\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba682881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 13] ML 고도화와 해석: XGBoost + SHAP (없으면 RF)\n",
    "if not df_.empty:\n",
    "    print(\"\\n--- 머신러닝 분석 ---\")\n",
    "    target_col = '통합지수'\n",
    "    raw_features = ['계절', '운전자연령대', '사고시간대', '도로종류', '법규위반_대분류',\n",
    "                    '기상상태', '도로형태', '노면상태', '성별', '주말여부', '분기', '러시아워']\n",
    "\n",
    "    feature_cols = [c for c in raw_features if c in df_.columns]\n",
    "    if len(feature_cols) == 0:\n",
    "        print(\"머신러닝 생략: 사용 가능 특징 없음\")\n",
    "    else:\n",
    "        use_cols = feature_cols + [target_col]\n",
    "        df_ml = df_[use_cols].dropna().copy()\n",
    "        if len(df_ml) > 0:\n",
    "            cat_cols = [c for c in feature_cols if df_ml[c].dtype == 'object']\n",
    "            df_ml_enc = pd.get_dummies(df_ml, columns=cat_cols, drop_first=True)\n",
    "            X = df_ml_enc.drop(columns=[target_col])\n",
    "            y = df_ml_enc[target_col]\n",
    "\n",
    "            MAX_ML_ROWS = 300_000\n",
    "            if len(X) > MAX_ML_ROWS:\n",
    "                X = X.sample(MAX_ML_ROWS, random_state=42)\n",
    "                y = y.loc[X.index]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            model_name = \"\"\n",
    "            if HAS_XGB:\n",
    "                model = xgb.XGBRegressor(n_estimators=400, max_depth=6, learning_rate=0.05, subsample=0.9, colsample_bytree=0.9, n_jobs=-1, random_state=42)\n",
    "                model_name = \"XGBoost\"\n",
    "            else:\n",
    "                model = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "                model_name = \"RandomForest\"\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            print(f\"{model_name} 성능: RMSE={rmse:.4f}, R2={r2:.4f}\")\n",
    "\n",
    "            # 변수 중요도 Top 20\n",
    "            try:\n",
    "                importances = model.feature_importances_\n",
    "                fi = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                sns.barplot(x=fi.values[:20], y=fi.index[:20])\n",
    "                plt.title(f'{model_name} 변수 중요도 Top 20'); plt.xlabel('중요도'); plt.ylabel('변수')\n",
    "                plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, f'feature_importance_top20_{model_name}.png')); plt.show()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # SHAP 해석 (가능할 때만)\n",
    "            if HAS_SHAP and HAS_XGB and model_name == \"XGBoost\":\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                # 큰 데이터 방지: 일부 샘플\n",
    "                sample_idx = np.random.choice(X.shape[0], size=min(20000, X.shape[0]), replace=False)\n",
    "                X_sample = X.iloc[sample_idx]\n",
    "                shap_values = explainer.shap_values(X_sample)\n",
    "                try:\n",
    "                    shap.summary_plot(shap_values, X_sample, max_display=20, show=False)\n",
    "                    plt.tight_layout(); plt.savefig(os.path.join(FIG_DIR, 'shap_summary.png')); plt.close()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            report_lines += [\n",
    "                \"[ML] 모델 결과\",\n",
    "                f\"- 모델: {model_name}\",\n",
    "                f\"- 성능: RMSE={rmse:.4f}, R2={r2:.4f}\",\n",
    "                \"\"\n",
    "            ]\n",
    "        else:\n",
    "            print(\"머신러닝 생략: 유효 행 없음\")\n",
    "else:\n",
    "    print(\"df_ 비어있음: 머신러닝 생략\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adfd9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [셀 14] 리포트 저장 및 해석 가이드\n",
    "report_path = os.path.join(REPORT_DIR, \"analysis_summary.md\")\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# 분석 요약 및 유의미성 검증 결과\\n\\n\")\n",
    "    f.write(\"본 리포트는 비모수 검정(Kruskal–Wallis)과 그룹별 95% 신뢰구간을 포함합니다.\\n\")\n",
    "    f.write(\"특징 조합의 유의성 탐색을 통해 '최소 몇 개의 특징을 묶어야\\n\")\n",
    "    f.write(\"유의미한 증감이 나타나는지'와 '어떤 조합이 유의미한지'를 제시합니다.\\n\\n\")\n",
    "    f.write(\"\\n\".join(report_lines))\n",
    "\n",
    "print(f\"리포트 저장 완료: {report_path}\")\n",
    "\n",
    "print(\"\"\"\n",
    "[의미성 검증 해석 가이드]\n",
    "- Kruskal–Wallis p<0.05: 범주 간 차이가 통계적으로 유의할 가능성이 높음(비모수).\n",
    "- 그룹별 95% 신뢰구간: 평균의 불확실성 범위 제시 → 구간 겹침 여부로 직관적 비교 가능.\n",
    "- 특징 조합 분석: 조합 크기 증가에 따라 p<0.05 비율이 상승하면,\n",
    "  해당 데이터에서는 '그 정도 차원수' 이상에서 상호작용 패턴이 드러난다는 의미.\n",
    "- 효과크기(평균범위): 유의미 조합 중 평균의 최대–최소 범위가 큰 조합은 정책 타깃팅 우선 후보.\n",
    "\n",
    "[발전 방향]\n",
    "- 노출 보정(통행량): 현재 가용치 없음 → 확보 시 통합지수 합계 대비 노출로 '위험률' 산출 권장.\n",
    "- 혼합효과모형: 요일/월/계절 등 시계열 교란을 임의효과로 모델링해 순효과 분리.\n",
    "- 범주군 축소/병합: 희소 범주를 대분류로 통합해 신뢰구간 폭 축소.\n",
    "- 정책 매핑: 상위 위험 장소 Top N × 주요 법규위반 대분류 × 도로형태 조합으로 맞춤 개입안 설계.\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
